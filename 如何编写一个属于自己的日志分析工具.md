## 前言

在日常的工作或者应急响应中，往往需要进行大量的日志分析。可当我们发现自己对shell命令并不太熟悉的时候，这似乎就演变成了一场-灾难（看到头秃~）。而在这种时候如果能有一个可以自动分析日志的工具，这将会大幅度地提高我们的工作效率，解放我们的双手（耶~）

提到日志分析工具，大家一定会想到ELK，Splunk这类重型日志分析工具。通过特定的搜索语法来匹配自己想要的数据。但其学习成本太高，普适性比较低（大佬勿喷）

废话不多说，让我们开始吧

## 前期准备

* 在线IDE：[https://repl.it/](https://repl.it/)，repl.it是一款云编辑器，它支持40多种语言，多人实时在线协作，联动github，还能将代码段转换为iframe嵌在网页、或是博客上。而此次我们将选用它作为我们的开放工具。

![图片](https://uploader.shimo.im/f/NQohAHwhUEEK9EJt.gif?fileGuid=dQPYXqghxTWvrkWj)

* python3.8+：相比旧版它有更多的新特性，写法优雅，编写效率也高。

* 一定的正则基础：不会正则的老哥，可以参考一下上篇 <都2021年了，你还不会正则？>


## 编写过程

既然要写日志分析工具，那首先一定要明白我们要分析的内容是什么。

一般来说，安全人员在日常工作或者应急响应中，都会出现需要对web日志分析的场景，从而开始定位攻击IP、其地理位置、攻击类型、以及攻击细节等。

那针对这种类型的日志分析，我们的代码思路可以是：

1. 对日志进行读取
2. 根据规则提取出ip、时间、payload等（正则）
3. 查询IP地址地理位置（借助第三方API，或开源IP库）
4. 整理并输出结果

是不是很简单？下面就是代码实现部分了~


### 1.读取日志

我们先定义一个函数，用于获取日志内容。

代码上层将以上下管理器 `with` 的方式来打开文件，这样做的好处在于该逻辑块完成后文件将被自动关闭。

并且，其中的 logs 对象本身就存在 `__iter__` 魔术方法。这意味着我们 可以借助`for` 来逐行读取，而不用一次将内容全部加载到内存，实现了对大文件的读取。


```python
def analysis(file, res):
    with file.open('r') as logs:
        datas = {}
        for line in logs:
            ...
```


很多同学喜欢先使用类似于 `logs.read()` 或 `logs.readline()` 这样操作，这是很浪费系统资源的哦！

### 2.匹配规则

这部分要涉及规则的编写（就是正则）,比如XSS漏洞的正则，可以基于自己的经验和网上搜集到的一些payload样本，进行编写



并且，我们以大类和小类层级关系来编写出一个字典以便于理解，如：

```python
rules = {
    'XSS': {
        'XSS':r"<(?:javascript|script|img|object|style|div|table|iframe|meta|body|svg|embed|a|input|marquee|link|xml|image|html).*(?:alert|onerror|document\.write|onload|onfocus|prompt|confirm)"
    },
    ...
}
```
而在我们需要使用的时候，我们将其转换为一维列表 `rule_pool` 以便代码使用

```python
import hashlib
def func_md5(data):
    return hashlib.new('md5', data.encode()).hexdigest()

rule_pool = {}
for key, items in rules.items():
    for name, code in items.items():
        rule_pool[func_md5(f'{key}-{name}')] = (key, name, re.compile(code, re.I), code)
```

规则写完之后，接下来就是匹配了

```python
for (key, name, rule, code) in rule_pool.values():
    matched = rule.search(line)
    if not matched:
        continue
```
### 3.匹配IP地理位置

* 在日志里面提取出IP

```python
def fetch_ip(line):
	rule = r'((2[0-4]\d|25[0-5]|[01]?\d\d?)\.){3}(2[0-4]\d|25[0-5]|[01]?\d\d?)'
	ip = re.search(rule,line).group()
	return ip
```

* 匹配IP地理位置

我们通过借助 **ipip.net** 提供的免费资源库来获取IP的地理信息

```python
import ipdb
IPDB = ipdb.District("ipip.ipdb")
```

接着就是匹配IP地理位置了，代码如下

```python
def get_geo(ip):
    datas = IPDB.find_map(ip, "CN")
    return f"{ip}-{datas.get('country_name','未知')}"
```
### 4.输出结果

然后我们将获取到的信息整合成一个字符串并将事件进行hash处理

```python
ip_data = get_geo(fetch_ip(line))
msg = f'[*]IP地址:{ip_data} \t[!]漏洞类型: {key}\t[+]漏洞细节: {name}\t\n'
event_hash = func_md5(msg)
```
这样好处是在同样事件出现的时候我们可以对其计数

```python
if code not in datas:
	datas[code] = [msg, 0]
    print(msg)
datas[code][-1] += 1
```

最后我们可以将该 `datas` 对象以json的方式存储起来，这我就不写啦

>  为了美观性我们还可以给我们的项目加个图标：[http://patorjk.com/software/taag](http://patorjk.com/software/taag)

## 结果展示

